import requests
import base64
import time
from io import BytesIO
from PIL import Image
import numpy as np
from pathlib import Path
from paddleocr import PaddleOCRVL
from fastapi import FastAPI, UploadFile, File
from pydantic import BaseModel
import uvicorn

# ==============================
# ğŸ”§ ì„¤ì •
# ==============================
OLLAMA_URL = "http://localhost:11434/api/generate"
LLAVA_MODEL = "llava:7b"       # ì´ë¯¸ì§€ ì„¤ëª…ìš©
TRANSLATE_MODEL = "gemma3:4b"  # í•œêµ­ì–´ ë²ˆì—­ìš©
MAX_SIZE = 1024                # ê¸´ ë³€ ë¦¬ì‚¬ì´ì¦ˆ ì œí•œ(px)

# ==============================
# PaddleOCR-VL ì´ˆê¸°í™”
# ==============================
print("ğŸ”„ PaddleOCR-VL ëª¨ë¸ ë¡œë”© ì¤‘...")
ocr_pipeline = PaddleOCRVL()
print("âœ… PaddleOCR-VL ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

# ==============================
# FastAPI ì•± ì´ˆê¸°í™”
# ==============================
app = FastAPI(title="Image Analysis API")

# ==============================
# ì…ë ¥ ëª¨ë¸ (URL)
# ==============================
class ImageURL(BaseModel):
    url: str

# ==============================
# ğŸ§© ì´ë¯¸ì§€ ë¡œë“œ + ë¦¬ì‚¬ì´ì¦ˆ
# ==============================
def load_and_resize_image_from_bytes(img_bytes, max_size=MAX_SIZE):
    img = Image.open(BytesIO(img_bytes)).convert("RGB")
    w, h = img.size
    if max(w, h) > max_size:
        scale = max_size / max(w, h)
        img = img.resize((int(w * scale), int(h * scale)), Image.LANCZOS)
    return img

def load_and_resize_image_from_url(url, max_size=MAX_SIZE):
    resp = requests.get(url)
    if resp.status_code != 200:
        raise RuntimeError(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {resp.status_code}")
    return load_and_resize_image_from_bytes(resp.content, max_size=max_size)

# ==============================
# ğŸ§  LLaVA + Gemma3 ì²˜ë¦¬
# ==============================
def run_llava_and_translate(img):
    start_time = time.time()

    # ì´ë¯¸ì§€ â†’ Base64
    buffer = BytesIO()
    img.save(buffer, format="JPEG", quality=85)
    img_b64 = base64.b64encode(buffer.getvalue()).decode("utf-8")

    # LLaVA ì˜ì–´ ì„¤ëª… ìš”ì²­
    payload_llava = {
        "model": LLAVA_MODEL,
        "prompt": "Describe this image shortly",
        "images": [img_b64],
        "stream": False
    }
    res1 = requests.post(OLLAMA_URL, json=payload_llava)
    if not res1.ok:
        raise RuntimeError(f"LLaVA ìš”ì²­ ì‹¤íŒ¨: {res1.status_code}\n{res1.text}")
    english_desc = res1.json()["response"].strip()

    # Gemma3 ë²ˆì—­ ìš”ì²­
    payload_trans = {
        "model": TRANSLATE_MODEL,
        "prompt": f"ë‚´ê°€ ë³´ë‚¸ ë¬¸ì¥ë§Œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì¤˜ ë‹¤ë¥¸ë§ì€ ì¶”ê°€í•˜ì§€ë§ˆ {english_desc}",
        "stream": False
    }
    res2 = requests.post(OLLAMA_URL, json=payload_trans)
    if not res2.ok:
        raise RuntimeError(f"Gemma3 ìš”ì²­ ì‹¤íŒ¨: {res2.status_code}\n{res2.text}")
    korean_desc = res2.json()["response"].strip()

    print(f"âœ… LLaVA ì™„ë£Œ ({round(time.time() - start_time, 2)}ì´ˆ)")
    return korean_desc


# ==============================
# ğŸ§¾ PaddleOCR ì²˜ë¦¬
# ==============================
def safe_serialize(obj):
    """JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜"""
    if isinstance(obj, (str, int, float, bool)) or obj is None:
        return obj
    if isinstance(obj, (list, tuple, set)):
        return [safe_serialize(i) for i in obj]
    if isinstance(obj, dict):
        return {str(k): safe_serialize(v) for k, v in obj.items()}
    if isinstance(obj, np.generic):
        return obj.item()
    if hasattr(obj, "__dict__"):
        return safe_serialize(obj.__dict__)
    return str(obj)

def extract_text_blocks(res_dict):
    """PaddleOCR-VL ê²°ê³¼ JSONì—ì„œ í…ìŠ¤íŠ¸ ë¸”ë¡ë§Œ ì¶”ì¶œ"""
    texts = []
    for block in res_dict.get("parsing_res_list", []):
        content = block.get("content", "").strip()
        if content:
            texts.append({
                "label": block.get("label", "unknown"),
                "bbox": block.get("bbox", []),
                "content": content
            })
    return texts

def run_ocr(img):
    """OCR ìˆ˜í–‰ í›„ ë¸”ë¡ë³„ í…ìŠ¤íŠ¸ì™€ í•©ì³ì§„ ê²°ê³¼ ë°˜í™˜"""
    start_time = time.time()
    img_np = np.array(img)
    result_list = []

    try:
        output = ocr_pipeline.predict(img_np)

        for idx, res in enumerate(output):
            res_dict = safe_serialize(res)
            texts = extract_text_blocks(res_dict)

            if not texts:
                continue

            combined_text = " ".join([t["content"] for t in texts])
            result_list.append(combined_text)

    except Exception as e:
        print(f"âš ï¸ OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    total_time = round(time.time() - start_time, 2)
    print(f"âœ… OCR ì™„ë£Œ ({total_time}ì´ˆ, {len(result_list)}ê°œ ë¸”ë¡)")

    # ë¸”ë¡ êµ¬ë¶„ ì¤„ë°”ê¿ˆìœ¼ë¡œ ì´ì–´ë¶™ì„
    return "\n".join(result_list)


# ==============================
# ğŸš€ FastAPI ì—”ë“œí¬ì¸íŠ¸
# ==============================
@app.post("/analyze_file")
async def analyze_file(file: UploadFile = File(...)):
    img_bytes = await file.read()
    img = load_and_resize_image_from_bytes(img_bytes)
    llava_korean = run_llava_and_translate(img)
    ocr_text = run_ocr(img)
    return {"llava": llava_korean, "ocr_text": ocr_text}

@app.post("/analyze_url")
async def analyze_url(data: ImageURL):
    img = load_and_resize_image_from_url(data.url)
    llava_korean = run_llava_and_translate(img)
    ocr_text = run_ocr(img)
    return {"llava": llava_korean, "ocr_text": ocr_text}


# ==============================
# â–¶ï¸ ì‹¤í–‰
# ==============================
if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)